---
title: "analysis_vi"
author: "Hunter York"
date: "11/22/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(ggplot2)
library(dplyr)
library(magrittr)
library(stringr)
library(readxl)
library(ggrepel)
library(foreign)
library(ipumsr)
library(data.table)
library(factoextra)



options
theme_set(theme_bw())

# load the data
setwd("/Users/hyork/Documents/projects/occupation/code")

weighted.var <- function(x, w, na.rm = FALSE) {
  if (na.rm) {
    w <- w[i <- !is.na(x)]
    x <- x[i]
  }
  sum.w <- sum(w)
  sum.w2 <- sum(w^2)
  mean.w <- sum(x * w) / sum(w)
  (sum.w / (sum.w^2 - sum.w2)) * sum(w * (x - mean.w)^2, na.rm =
                                       na.rm)
}



# acs <- readstata13::read.dta13("../inputs/cps_00009.dta")
# acs2 <- fread("../inputs/cps_00008.csv")
# acs <- cbind(acs, acs2[,.(OCC2010, OCC1990,OCC1950, OCC, OCCLY,OCC50LY, OCC90LY, OCC10LY, HOURWAGE)])
# acs <- acs[acs$empstat == "at work" &
#                              (acs$schlcoll %like% "does not attend|niu"| is.na(acs$schlcoll)) &
#                              as.numeric(as.character(acs$age)) %in% 25:64 &
#                             acs$wkswork1 >= 30 &
#                              acs$incwage != 99999999 &
#                              acs$incwage > 0,]
# acs <- data.table(acs)
# #keep vars
# acs <- acs[,.(race, hispan, year,asecwt, sex, age, schlcoll,educ, empstat,OCC,OCC2010,OCC1990, ind,ind1990, classwkr, ahrsworkt,wkswork1, uhrsworkly,classwly,workly,OCCLY,indly,OCC90LY,OCC1950, OCC50LY,ind90ly,OCC10LY, incwage, HOURWAGE)]

# subset


#saveRDS(acs, "../inputs/cps_00008.rds")
acs <- readRDS( "../inputs/cps_00008.rds")

# derive a 5-year age var
acs[, age_cat := paste0(floor(as.numeric(as.character(age))/5)*5,
                        " to ", 
                        floor(as.numeric(as.character(age))/5)*5 + 4)]

# make first dig var
#acs[, first_dig := substr(occ, 1,1)]

# make map for first dig categories
# map <- data.table(first_dig = as.character(0:9), 
#                   occ_categ = c("Professional", "Clerical", "Service",
#                                 "Agricultural, etc.", "Skilled", "Skilled",
#                                 "Semiskilled", "Semiskilled", "Unskilled",
#                                 "Unskilled"))
# acs <- merge(acs, map, by = "first_dig")

# # crosswalk to ppp
# ppp <- read_excel("../ref/CPI_U_RS.xlsx") %>% data.table
# ppp[1, year := 1940]
# ppp[1, cpi := 33]
# ppp[, year := as.character(year)]
# ppp[, xwalk_fac := cpi/369.8]
# acs <- merge(acs, ppp, by = "year")
# acs[, incwage := incwage/xwalk_fac]
# create log inc wage
acs[, log_incwage := log(incwage + 1)]

#
#acs <- acs[year %in% seq(1990,1999,3)]

# load occ_soc xwalk
occ_xwalk <- data.table(read_excel("../ref/nem-occcode-cps-crosswalk.xlsx"))
names(occ_xwalk) <- occ_xwalk[4,] %>% unlist()
occ_xwalk <- occ_xwalk[-(1:4),]
occ_xwalk[, OCCSOC := gsub("-", "", `Hybrid SOC Code`)]

# now create skills dataset
skills_2009 <- read.delim('../ref/db_14_0 2009.7/Skills.txt') %>% data.table()
skills_2013 <-  read.delim('../ref/db_18_0_2013.7/Skills.txt') %>% data.table()
skills_2018 <- read_excel("../ref/db_22_2_excel 2018.2/Skills.xlsx") %>% data.table()
skills_2009[, year := 2009]
skills_2013[, year := 2013]
skills_2018[, year := 2018]
setnames(skills_2018, names(skills_2018), gsub(" ", ".", names(skills_2018), fixed = T))
skills_2018[, `O.NET.SOC.Code` := `O*NET-SOC.Code`]
skills <- rbindlist(list(skills_2009, skills_2013, skills_2018), fill = T)
skills <- skills[, .(O.NET.SOC.Code, Element.Name, Scale.ID, Data.Value, Standard.Error, year)]
skills[, Element.Name := paste0("skl_", Element.Name)]
# add abilities
abilities_2009 <- read.delim('../ref/db_14_0 2009.7/Abilities.txt') %>% data.table()
abilities_2013 <-  read.delim('../ref/db_18_0_2013.7/Abilities.txt') %>% data.table()
abilities_2018 <- read_excel("../ref/db_22_2_excel 2018.2/Abilities.xlsx") %>% data.table()
abilities_2009[, year := 2009]
abilities_2013[, year := 2013]
abilities_2018[, year := 2018]
setnames(abilities_2018, names(abilities_2018), gsub(" ", ".", names(abilities_2018), fixed = T))
abilities_2018[, `O.NET.SOC.Code` := `O*NET-SOC.Code`]
abilities <- rbindlist(list(abilities_2009, abilities_2013, abilities_2018), fill = T)
abilities <- abilities[, .(O.NET.SOC.Code, Element.Name, Scale.ID, Data.Value, Standard.Error, year)]
abilities[, Element.Name := paste0("abl_", Element.Name)]

# add knowledge
knowledge_2009 <- read.delim('../ref/db_14_0 2009.7/Knowledge.txt') %>% data.table()
knowledge_2013 <-  read.delim('../ref/db_18_0_2013.7/Knowledge.txt') %>% data.table()
knowledge_2018 <- read_excel("../ref/db_22_2_excel 2018.2/Knowledge.xlsx") %>% data.table()
knowledge_2009[, year := 2009]
knowledge_2013[, year := 2013]
knowledge_2018[, year := 2018]
setnames(knowledge_2018, names(knowledge_2018), gsub(" ", ".", names(knowledge_2018), fixed = T))
knowledge_2018[, `O.NET.SOC.Code` := `O*NET-SOC.Code`]
knowledge <- rbindlist(list(knowledge_2009, knowledge_2013, knowledge_2018), fill = T)
knowledge <- knowledge[, .(O.NET.SOC.Code, Element.Name, Scale.ID, Data.Value, Standard.Error, year)]
knowledge[, Element.Name := paste0("knl_", Element.Name)]

#
skills <- rbindlist(list(skills, knowledge, abilities))

#
skills <- skills[Scale.ID == "LV"]
# reformate onet codes to merge
skills[, OCCSOC := gsub("-", "", substr(O.NET.SOC.Code,1,7))]
skills <- skills[,.(Data.Value = mean(Data.Value),
                    Standard.Error = mean(as.numeric(Standard.Error))), by = .(Element.Name,Scale.ID, OCCSOC)]

# chack to see which occ codes are missing
occ_xwalk[!OCCSOC %in% unique(skills$OCCSOC), unique(OCCSOC)]

# 
skills[, Element.Name := paste0(Element.Name, ".", Scale.ID)]
skills[,Data.Value := percent_rank(Data.Value), by = .(Element.Name, Scale.ID)]
skills_wide <- dcast(skills, OCCSOC   ~Element.Name, value.var = "Data.Value")
res.pca <- prcomp(skills_wide[,2:71], scale = TRUE, center = T)
# skills wide
skills_sum <- skills_wide
skills_sum[, pc1 := predict(res.pca, newdata = .SD)[,1], .SDcols = names(skills_sum)]
skills_sum[, pc2 := predict(res.pca, newdata = .SD)[,2], .SDcols = names(skills_sum)]
skills_sum[, pc3 := predict(res.pca, newdata = .SD)[,3], .SDcols = names(skills_sum)]
skills_sum[, pc4 := predict(res.pca, newdata = .SD)[,4], .SDcols = names(skills_sum)]

skills_sum[, skl_tech_skill.LV := skl_Programming.LV + `skl_Complex Problem Solving.LV` +
             `skl_Mathematics.LV`  + skl_Science.LV + `skl_Systems Analysis.LV` + 
             skl_Troubleshooting.LV]
# skills_sum[, skl_tech_skill.IM := skl_Programming.IM + `skl_Complex Problem Solving.IM` +
#              `skl_Mathematics.IM`  + skl_Science.IM + `skl_Systems Analysis.IM` + 
#              skl_Troubleshooting.IM]
skills_sum[, average_value_skills := rowMeans(.SD), .SDcols = rownames(res.pca$rotation)[rownames(res.pca$rotation) %like% "LV" & rownames(res.pca$rotation) %like% "skl"]]
skills_sum[, average_value_abilities := rowMeans(.SD), .SDcols = rownames(res.pca$rotation)[rownames(res.pca$rotation) %like% "LV" & rownames(res.pca$rotation) %like% "abl"]]
skills_sum[, average_value_knowledge := rowMeans(.SD), .SDcols = rownames(res.pca$rotation)[rownames(res.pca$rotation) %like% "LV" & rownames(res.pca$rotation) %like% "knl"]]

skills_sum <- merge(skills_sum, occ_xwalk, by = "OCCSOC")


# collapse to OCCSOC
vars <- names(skills_wide)[-1]
skills_final <- skills_sum[,lapply(.SD, mean), .SDcols = vars, by = .(`CPS Code`, `CPS Occupational Title`)]
acs[, OCC2010 := as.character(OCC2010)]

#standardize occ2010 to match occ2019
acs[,.(OCC2010, OCC1990)] %>% unique -> temp
temp <- temp[!duplicated(temp$OCC2010)]
skills_final <- merge(skills_final, temp, by.x = "CPS Code", by.y = "OCC2010", all.x = T)
vars_temp <- names(skills_final)[!names(skills_final) %like% "CPS|OCC"]
skills_final[, (vars_temp) := lapply(.SD, mean, na.rm = T), by = OCC1990, .SDcols = vars_temp]
skills_final[,OCC1990 := NULL]

#clean up memory
rm(list = ls()[!ls() %in% c("acs", "vars", "weighted.var", "skills_final")])
```


### See how Adjusted Mutual Information Looks (Per Cheng and Park)

The following section compares the above classification system to Micro, Meso, and Macro occupation schedules using the 1950 occupation basis, per Siwei's crosswalk. This would ideally be updated to a more recent basis.

```{r}
# cheng xwalk
cheng <- data.table(readstata13::read.dta13("../ref/occ1950_mc_xwalk_70.dta"))
cheng[, occ1950 := gsub("[^A-Za-z0-9]", "", tolower(occ1950))]

# occ50 recode
occ50_recode <- fread("../ref/occ1950_recode.csv")
occ50_recode <- occ50_recode[,1:2]
names(occ50_recode) <- unlist(occ50_recode[1, ])
occ50_recode <- occ50_recode[-1,]
occ50_recode <- occ50_recode[!is.na(as.numeric(occ1950_num))]
occ50_recode[, occ1950 := gsub("[^A-Za-z0-9]", "", tolower(occ1950))]

# merge
cheng <- merge(cheng, occ50_recode[,.(occ1950, occ1950_num)], all.x = T)

#fix the stragglers
fix <- cheng[is.na(occ1950_num)]
candidates <- occ50_recode[!occ1950 %in% cheng$occ1950]

for(c.fix in 1:nrow(fix)){
  goal <- substr(fix[c.fix, occ1950],1,7)
  new <- candidates[candidates$occ1950 %like% goal, occ1950_num]
  if(length(new) == 1){fix[c.fix, new_occ1950_num := new]}
}


fix[is.na(new_occ1950_num), new_occ1950_num := c(43, 34, 44, 603, 16, 46, 605,94, 19,48,69,84,26,23,27,29)]

cheng <- merge(cheng, fix[,.(occ1950, new_occ1950_num)], by = "occ1950", all.x = T)
cheng[is.na(occ1950_num), occ1950_num := new_occ1950_num]
cheng[, occ1950_num := as.numeric(occ1950_num)]
cheng[, new_occ1950_num := NULL]
setnames(cheng, "occ1950_num", "OCC1950")
cheng[, occ1950 := NULL]

factorr <- function(x){ifelse(is.character(x), return(factor(x)), return(x))}
cheng[,names(cheng) := lapply(.SD, factorr), .SDcols = names(cheng)]

names(acs)[!names(acs) %like% "skl|knl|abl"] -> temp_vars
acs[, (temp_vars) := lapply(.SD, factorr), .SDcols = temp_vars]

#acs <- merge(acs, cheng, by.x = "OCC1950", by.y = "occ1950_num", all.x = T)
acs[,c("race", "hispan", "schlcoll","empstat","ahrsworkt",
       "wkswork1","uhrsworkly","classwly","workly",
       "HOURWAGE"):= NULL]

acs <- acs[cheng, on = "OCC1950"]

setnames(acs, c("mesoocc", "macroocc", "microocc"), paste0(c("mesoocc", "macroocc", "microocc"), "_current"))

setnames(cheng, "OCC1950", "OCC50LY")

acs <- acs[cheng, on = "OCC50LY"]

setnames(acs, c("mesoocc", "macroocc", "microocc"), paste0(c("mesoocc", "macroocc", "microocc"), "_ly"))

# loop over scheme and calculate concordance
for(c.scheme in  c( "mesoocc", "macroocc", "microocc")){
  acs[,paste0(c.scheme, "_conc") := get(paste0(c.scheme, "_ly")) == get(paste0(c.scheme, "_current")) ]
}


```



```{r}
# merge it all
acs <- merge(acs, skills_final, 
             all.x = T,
             by.x = "OCC2010",
             by.y = "CPS Code")

# 

# merge on both new and old jobs
setnames(acs, vars, paste0(vars, "_current"))
setnames(acs, "CPS Occupational Title","CPS Occupational Title_current")
# merge it all
acs[, OCC10LY := as.character(OCC10LY)]
acs <- merge(acs, skills_final, 
             all.x = T,
             by.x = "OCC10LY",
             by.y = "CPS Code")

setnames(acs, vars, paste0(vars, "_ly"))
setnames(acs, "CPS Occupational Title","CPS Occupational Title_ly")

# subset to places where people have moved jobs
acs_moved <- acs[OCC2010 != OCC10LY]

# calculate flows
acs_flows <- acs[!is.na(`CPS Occupational Title_current`) & 
                   !is.na(`CPS Occupational Title_ly`),.(mvmt = .N), by = .(OCC2010, OCC10LY, `CPS Occupational Title_current`, `CPS Occupational Title_ly`)]

# graph top movement
temp <- acs_moved[, .N, by = OCC10LY] %>% .[order(N, decreasing = T)] %>% .[1:7, OCC10LY]
acs_flows[,rank := frankv(mvmt, order = -1L, ties.method = "first"), by = OCC10LY]
acs_flows[, OCC_title_ly := paste0(str_sub(`CPS Occupational Title_ly`, 1, 15), 
                                   "...")]
acs_flows[, OCC_title_current:= paste0(str_sub(`CPS Occupational Title_current`, 1, 15), 
                                       "...")]

acs_flows[, OCC_title_current := factor(OCC_title_current)]

# 
```

# Create occupation categories based on skill first, see how well they track with flows

## Overview

In the following section, I will attempt to create some sort of aggregation of occupational classifications based on skills alone. I aim to create 82 classes to compare with the micro-class scheme proffered by Grusky et al., but many decisions are fickle and subject to my own bias. As a first pass, I'm creating 80 classes using 5 quintiles of pc1, 4 quartiles of pc2, and 2 quantiles of pc3 and pc4. Each combination of these latent variables will correspond to a skills-based occupation category. 


### Compute skills distance between all job movements

For this exercise, I'm defining distance in skills as the geometric mean of distance between each variable. Thus:

$$D_{i, j} = \prod_n^4{|PC_n^{i,j} - PC_n^{i,j}|}$$

Where: $D_{i,j}$ is the skill distance from job i to job j.

The following graph shows the distribution of skill distance for all occupational movements.

```{r}

for(c.skill in vars){
  #acs[, paste0(c.skill, "_distance") := abs(get(paste0(c.skill, '_current')) - get(paste0(c.skill, '_ly')))]
  acs[, paste0(c.skill, "_diff") := (get(paste0(c.skill, '_current')) - get(paste0(c.skill, '_ly')))]
  
}

# subset to flows
skills_flows <- acs[OCC10LY != OCC2010]

# # graph distribution
# ggplot(skills_flows[!(OCC2010 == 4760 & OCC10LY == 4850),.SD, .SDcols = paste0(vars[!vars %like% "skills|pc"], "_distance")] %>% melt()) + 
#   geom_histogram(aes(x = value)) + 
#   facet_wrap(~variable) + 
#   xlim(0,1) + 
#   geom_abline(intercept = 2831.867, slope = -2831.867)


ggplot(skills_flows[ind1990 == ind90ly,.SD,
                    .SDcols = paste0(vars[!vars %like% "skills|pc|tech|IM|average|skl|knl"], "_diff")] %>% melt()) + 
  geom_histogram(aes(x = value), bins = 100) + 
  geom_vline(aes(xintercept = mean, group = variable), 
             
             data = skills_flows[ind1990 == ind90ly,.SD, .SDcols = paste0(vars[!vars %like%"skills|pc|tech|IM|average|skl|knl"], "_diff")] %>%
               melt() %>% .[,.(mean = mean(value, na.rm = T)), by = variable],
             
             color = "blue" )+
  facet_wrap(~variable) + 
  
  xlim(-1,1)   +
  geom_vline(xintercept = 0, color = "red")

ggplot(skills_flows[ind1990 == ind90ly,.SD, 
                    .SDcols = paste0(vars[!vars %like% "skills|pc|tech|IM|average|skl|knl"], "_diff")] %>% melt()) + 
  geom_histogram(aes(x = value), bins = 100) + 
  geom_vline(aes(xintercept = mean, group = variable), 
             
             data = skills_flows[ind1990 == ind90ly,.SD, .SDcols = paste0(vars[!vars %like% "skills|pc|tech|LV"], "_diff")] %>% melt() %>% .[,.(mean = mean(value, na.rm = T)), by = variable],
             
             color = "blue" )+
  facet_wrap(~variable) + 
  
  xlim(-1,1)  +
  geom_vline(xintercept = 0, color = "red")


acs[,paste0(vars, "_diff") := NULL]
```

Right skewed = good! More people are shifting between jobs with similar skillsets than dissimilar skill sets.




### Calculate % of job moves that remain within class for each class

This is obviously biased by the number of classes. I think this can be standardzied mathematically, but I haven't tried to figure that out. 


### See the extent to which interoccupation mobility is defined by upwards mobility in terms of skill



## Do a grid search to find optimal number of skill bins



### try network

```{r}
# temp <- estimateNetwork(data = acs[,.SD, .SDcols = names(acs)[names(acs) %like% "LV_current" & !names(acs) %like% "tech_skill|pc"]] %>% setnames(., names(.), substr(names(.), 1,15)), 
#                         default = "EBICglasso")
# plot(temp, layout = "spring", labels = colnames(temp))
# plot(temp, layout = "spring")

rm(list = ls()[!ls() %in% c("acs", "vars", "weighted.var")])
##################
acs <- copy(acs[complete.cases(acs[,.SD, .SDcols = names(acs)[names(acs) %like% "LV" & !names(acs) %like% "tech_skill|average|pc"]])])

## check out missing cases above!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1
# df <- data.table(rbind(acs[, .SD, .SDcols = names(acs)[names(acs) %like% "LV_current" & !names(acs) %like% "tech_skill|average|pc"]], acs[, .SD, .SDcols = names(acs)[names(acs) %like% "LV_ly" & !names(acs) %like% "tech_skill|average|pc"]] %>% setnames(., gsub("_ly", "_current", names(.)))))

df <- acs[!duplicated(acs$OCC2010), .SD, .SDcols = names(acs)[names(acs) %like% "skl|knl|abl|OCC2010" & names(acs) %like% "current|OCC2010"]]
df_occ <- df[,OCC2010]
df[, OCC2010 := NULL]

stats::kmeans(df, centers = 30) -> temp

df_temp <- data.table(OCC2010 = df_occ, kmeans_cluster = temp$cluster)

acs <- merge(acs, df_temp, by = "OCC2010")
setnames(acs, "kmeans_cluster", "kmeans_cluster_current")

df_temp <- data.table(OCC10LY = df_occ, kmeans_cluster = temp$cluster)
acs <- merge(acs, df_temp, by = "OCC10LY")
setnames(acs, "kmeans_cluster", "kmeans_cluster_ly")

#lapply(seq(5,105,10), optr) -> out


overlap_micro_count <- acs[,.(N = length(unique(OCC2010))), by = .(microocc_current, kmeans_cluster_current)]
overlap_micro_count[,kmeans_cluster_current := factor(kmeans_cluster_current, 
                                                      levels = acs[,.(mean = mean(average_value_skills_current)), by = kmeans_cluster_current] %>% .[order(mean, decreasing = T)] %>% .[,kmeans_cluster_current])]
ggplot(overlap_micro_count) +
  geom_tile(aes(y = microocc_current, x = kmeans_cluster_current, fill = N), alpha = .75) +
  geom_text(aes(y = microocc_current, x = kmeans_cluster_current, label = N), size = 2) +
  theme(axis.text.x = element_text(angle = 90)) +
  ggtitle("Micro-class and Skills-Based Class Concordance\n(Number of Overlapping Occupations)")+
  scale_fill_viridis_c( trans = "log10")
# now compute AMI
ami_scores <- acs[complete.cases(acs[,.(kmeans_cluster_current, macroocc_current)]),
                  .(macro = aricode::AMI(macroocc_current, kmeans_cluster_current), 
                    meso = aricode::AMI(mesoocc_current, kmeans_cluster_current),
                    micro = aricode::AMI(microocc_current, kmeans_cluster_current)), by = .(year)]

ami_scores %>% 
  melt(., id.var = "year") %>% 
  ggplot(.) + 
  geom_line(aes(x = year, y = value, linetype = variable))

# judge concordance
acs[, kmeans_cluster_conc := ifelse(kmeans_cluster_current == kmeans_cluster_ly, 1,0)]
num_correct <- acs[OCC1950 != OCC50LY, colSums(.SD, na.rm = T), .SDcols = names(acs)[names(acs) %like% "conc"]]
total <- acs[OCC1950 != OCC50LY , nrow(.SD)]
num_correct <- num_correct/total
num_cats <- acs[OCC1950 != OCC50LY , lapply(.SD, FUN = function(x){length(unique(x))}), .SDcols = names(acs)[names(acs) %like% "occ_ly|bin_ly|kmeans_cluster_ly"]]

# get matrix of means and compute distances between each cluster
# geometric means
centers <- temp$centers
centers_long <- melt(centers)
centers_long <- merge(centers_long, centers_long, by = "Var2", allow.Cartesian = T)
centers_dist <- data.table(centers_long)[,.(geo_mean_dist = prod(abs(value.x - value.y)) ^ (1/length(value.x))),
                                         by = .(Var1.x, Var1.y)]
setnames(centers_dist, c("kmeans_cluster_current", "kmeans_cluster_ly", "geo_mean_dist"))

#
acs <- merge(acs, centers_dist, by = c("kmeans_cluster_current", "kmeans_cluster_ly"))

#graph dist
ggplot(acs[OCC2010 != OCC10LY]) + 
  geom_density(aes(x = geo_mean_dist))

ggplot(acs[OCC2010 != OCC10LY & ind == indly]) + 
  geom_density(aes(x = geo_mean_dist))

#
acs[, source_kmeans_N := .N, by = kmeans_cluster_ly]

acs[, kmeans_cluster_current := factor(kmeans_cluster_current, 
                                       levels = centers_dist[kmeans_cluster_current == 1] %>%
                                         .[order(geo_mean_dist)] %>% .[,kmeans_cluster_ly])]
acs[, kmeans_cluster_ly := factor(kmeans_cluster_ly, 
                                  levels = centers_dist[kmeans_cluster_current == 1] %>%
                                    .[order(geo_mean_dist)] %>% .[,kmeans_cluster_ly])]


acs[OCC10LY != OCC2010,.(N = .N, source_kmeans_N = unique(source_kmeans_N)),
    by= .(kmeans_cluster_current, kmeans_cluster_ly)] %>% 
  .[, total := sum(N), by = kmeans_cluster_ly] %>% 
  .[, prop := N/source_kmeans_N] %>% 
  .[N >= 10] %>% 
  ggplot() + 
  geom_point(aes(y = as.factor(kmeans_cluster_current), x = as.factor(kmeans_cluster_ly), color = prop, size = N)) + 
  scale_color_viridis_c(trans = "log10") +
  scale_radius(trans = "log10")+
  geom_abline(yintercept = 0, slope = 1, color= "red")
```


### Display difference in within-cluster variance in skills/knowledge/abilities as k increases

```{r}
df <- acs[!duplicated(acs$OCC2010), .SD, .SDcols = names(acs)[names(acs) %like% "skl|knl|abl|OCC2010" & names(acs) %like% "current|OCC2010"]]
df_occ <- df[,OCC2010]
df[, OCC2010 := NULL]

acs[, c(paste0(vars, "_current"), paste0(vars, "_ly")) := NULL]

optr <- function(k){
  stats::kmeans(df, centers = k) -> temp2
  return(data.table(k =k, tot_withinss = temp2$tot.withinss))
}

lapply(1:250, optr) %>% rbindlist -> optr_out
ggplot(optr_out) + 
  geom_point(aes(x = k, y = tot_withinss))

```

### See how different k affects mobility

Set number of k to correspond with meso, micro, macro class schemas and some other random numbers.

k = {4,9,67, 20,30,40,50,80,90,100,120}

```{r}

testr <- function(k){
  stats::kmeans(df, centers = k) -> temp2
  df_temp <- data.table(OCC2010 = df_occ, kmeans_cluster = temp2$cluster)
  
  acs <- merge(acs, df_temp, by = "OCC2010")
  setnames(acs, "kmeans_cluster", paste0("kmeans_cluster_", k, "_current"))
  
  df_temp <- data.table(OCC10LY = df_occ, kmeans_cluster = temp2$cluster)
  acs <- merge(acs, df_temp, by = "OCC10LY")
  setnames(acs, "kmeans_cluster", paste0("kmeans_cluster_", k, "_ly"))
  
  
  centers <- temp2$centers
  centers_long <- melt(centers)
  centers_long <- merge(centers_long, centers_long, by = "Var2", allow.Cartesian = T)
  centers_dist <- data.table(centers_long)[,.(geo_mean_dist = prod(abs(value.x - value.y)) ^ (1/length(value.x))),
                                           by = .(Var1.x, Var1.y)]
  setnames(centers_dist, c(paste0("kmeans_cluster_", k, "_current"), 
                           paste0("kmeans_cluster_", k, "_ly"), paste0("geo_means_", k, "_dist")))
  
  #
  acs <- merge(acs, centers_dist, by = c(paste0("kmeans_cluster_", k, "_current"),
                                         paste0("kmeans_cluster_", k, "_ly")))
  
  acs[,paste0("kmeans_cluster_", k, "_conc") := ifelse(get(paste0("kmeans_cluster_", k, "_current")) == 
                                                         get(paste0("kmeans_cluster_", k, "_ly")),1,0)]
  
  acs[, paste0("source_kmeans_", k, "_N") := .N, by = get(paste0("kmeans_cluster_", k, "_ly"))]
  
  acs[, paste0("kmeans_cluster_", k, "_current") := factor(get(paste0("kmeans_cluster_", k, "_current")), 
                                                           levels = centers_dist[get(paste0("kmeans_cluster_", k, "_current")) == 1] %>%
                                                             .[order(get(paste0("geo_means_", k, "_dist")))] %>%
                                                             .[,get(paste0("kmeans_cluster_", k, "_ly"))])]
  acs[, paste0("kmeans_cluster_", k, "_ly") := factor(get(paste0("kmeans_cluster_", k, "_ly")), 
                                                      levels = centers_dist[get(paste0("kmeans_cluster_", k, "_current")) == 1] %>%
                                                        .[order(get(paste0("geo_means_", k, "_dist")))] %>%
                                                        .[,get(paste0("kmeans_cluster_", k, "_ly"))])]
  
  
  
  return(acs[,.SD, .SDcols = c(paste0("kmeans_cluster_", k, "_current"),
                               paste0("kmeans_cluster_", k, "_ly"),
                               paste0("geo_means_", k, "_dist"),
                               paste0("kmeans_cluster_", k, "_conc"),
                               paste0("source_kmeans_", k, "_N") )])
  
}

c(4,9,67, 20,30,40,50,80,90,100,120) -> k_cand
lapply(k_cand, testr) -> testr_out

acs <- bind_cols(acs, testr_out)



### check concordance of micro meso and macro first

num_correct <- acs[OCC1950 != OCC50LY & !is.na(kmeans_cluster_30_current),
                   colSums(.SD, na.rm = T), .SDcols = names(acs)[names(acs) %like% "conc"]]
total <- acs[OCC1950 != OCC50LY & !is.na(skill_bin_conc) & !is.na(skill_bin_current) & !is.na(skill_bin_ly), nrow(.SD)]
num_correct <- num_correct/total
num_cats <- acs[OCC1950 != OCC50LY & !is.na(skill_bin_conc) & !is.na(skill_bin_current) & !is.na(skill_bin_ly), lapply(.SD, FUN = function(x){length(unique(x))}), .SDcols = names(acs)[names(acs) %like% "occ_ly|bin_ly"]]


```


```{r}

for(k in k_cand){
  acs[OCC10LY != OCC2010,.(N = .N, source_kmeans_N = unique(get(paste0("source_kmeans_", k, "_N") ))),
      by= .(get(paste0("kmeans_cluster_", k, "_current")), get(paste0("kmeans_cluster_", k, "_ly")))] %>% 
    .[, total := sum(N), by = get.1] %>% 
    .[, prop := N/source_kmeans_N] %>% 
    .[N >= 10] %>% 
    ggplot() + 
    geom_point(aes(y = get,
                   x = get.1, color = prop, size = N)) + 
    scale_color_viridis_c(trans = "log10") +
    scale_radius(trans = "log10")+
    geom_abline(yintercept = 0, slope = 1, color= "red") +
    scale_x_discrete(drop = F)+
    scale_y_discrete(drop = F)
}
```



```{r}
df_temp <- data.table(OCC2010 = df_occ, kmeans_cluster = temp$cluster)

acs <- merge(acs, df_temp, by = "OCC2010")
setnames(acs, "kmeans_cluster", "kmeans_cluster_current")

df_temp <- data.table(OCC10LY = df_occ, kmeans_cluster = temp$cluster)
acs <- merge(acs, df_temp, by = "OCC10LY")
setnames(acs, "kmeans_cluster", "kmeans_cluster_ly")

# optimize k
optr <- function(k){
  stats::kmeans(df, centers = k) -> temp2
  return(temp2$tot.withinss)
}


# gg_list <- list()
# q <- 0
# for(k in seq(10,110,20)){
#   q <- q + 1
#   print(k)
#   df <- data.table(rbind(acs[, .SD, .SDcols = names(acs)[names(acs) %like% "LV_current" & !names(acs) %like% "tech_skill|pc"]], acs[, .SD, .SDcols = names(acs)[names(acs) %like% "LV_ly" & !names(acs) %like% "tech_skill|pc"]] %>% setnames(., gsub("_ly", "_current", names(.)))))
#   stats::kmeans(df, centers = k) -> temp
#   
#   # assign clusters
#   acs[, kmeans_cluster_current := temp$cluster[1:nrow(acs)]]
#   acs[, kmeans_cluster_ly := temp$cluster[(nrow(acs) + 1):(nrow(acs)*2)]]
#   
#   #
#   # get matrix of means and compute distances between each cluster
#   # geometric means
#   centers <- temp$centers
#   centers_long <- melt(centers)
#   centers_long <- merge(centers_long, centers_long, by = "Var2", allow.Cartesian = T)
#   centers_dist <- data.table(centers_long)[,.(geo_mean_dist = prod(abs(value.x - value.y)) ^ (1/length(value.x))),
#                                            by = .(Var1.x, Var1.y)]
#   setnames(centers_dist, c("kmeans_cluster_current", "kmeans_cluster_ly", "geo_mean_dist"))
#   
#   #
#   acs[, geo_mean_dist := NULL]
#   acs <- merge(acs, centers_dist, by = c("kmeans_cluster_current", "kmeans_cluster_ly"))
#   
#   #
#   acs[, source_kmeans_N := .N, by = kmeans_cluster_ly]
#   centers <- data.table(centers)
#   centers[,total_skills := rowSums(.SD), .SDcols = names(centers)]
#   
#   acs[, kmeans_cluster_current := factor(kmeans_cluster_current, 
#                                          levels = centers[, order(total_skills)])]
#   acs[, kmeans_cluster_ly := factor(kmeans_cluster_ly, 
#                                     levels = centers[, order(total_skills)])]
#   
#   
#   gg <- acs[OCC10LY != OCC2010,.(N = .N, source_kmeans_N = unique(source_kmeans_N)),
#             by= .(kmeans_cluster_current, kmeans_cluster_ly)] %>% 
#     .[, total := sum(N), by = kmeans_cluster_ly] %>% 
#     .[, prop := N/source_kmeans_N] %>% 
#     .[N >= 10] %>% 
#     ggplot()+
#       geom_point(aes(y = (kmeans_cluster_current), x = (kmeans_cluster_ly), color = prop, size = N)) + 
#   scale_color_viridis_c(trans = "log10") +
#   scale_radius(trans = "log10")+
#   geom_abline(yintercept = 0, slope = 1, color= "red") +
#   scale_x_discrete(labels = centers[, order(total_skills)],
#                    breaks = centers[, order(total_skills)], drop = F)+
#   scale_y_discrete(labels = centers[, order(total_skills)],
#                    breaks = centers[, order(total_skills)], drop = F)+
#   theme(axis.text.x = element_text(angle = 90))
#   
#   print(gg)
# 
# }


```

### See how well each scheme predicts log earnings

```{r}
mod <- lm(log_incwage ~ as.factor(kmeans_cluster_current), acs[year == 1999])
mod2 <- lm(log_incwage ~ as.factor(mesoocc_current), acs[year == 1999])
stats::AIC(mod2)
stats::AIC(mod)
```