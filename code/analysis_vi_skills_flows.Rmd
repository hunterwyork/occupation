---
title: "analysis_vi"
author: "Hunter York"
date: "11/22/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(ggplot2)
library(dplyr)
library(magrittr)
library(stringr)
library(readxl)
library(ggrepel)
library(foreign)
library(ipumsr)
library(data.table)
library(factoextra)



options
theme_set(theme_bw())

# load the data
setwd("/Users/hyork/Documents/projects/occupation/code")

weighted.var <- function(x, w, na.rm = FALSE) {
  if (na.rm) {
    w <- w[i <- !is.na(x)]
    x <- x[i]
  }
  sum.w <- sum(w)
  sum.w2 <- sum(w^2)
  mean.w <- sum(x * w) / sum(w)
  (sum.w / (sum.w^2 - sum.w2)) * sum(w * (x - mean.w)^2, na.rm =
                                       na.rm)
}



# acs <- readstata13::read.dta13("../inputs/cps_00010.dta")
# acs2 <- fread("../inputs/cps_00008.csv")
# acs <- cbind(acs, acs2[,.(OCC2010, OCC1990,OCC1950, OCC, OCCLY,OCC50LY, OCC90LY, OCC10LY, HOURWAGE)])
# acs <- acs[acs$empstat == "at work" &
#                              (acs$schlcoll %like% "does not attend|niu"| is.na(acs$schlcoll)) &
#                              as.numeric(as.character(acs$age)) %in% 25:64 &
#                             acs$wkswork1 >= 30 &
#                              acs$incwage != 99999999 &
#                              acs$incwage > 0,]
# acs <- data.table(acs)
# #keep vars
# acs <- acs[,.(race, hispan, year,asecwt, sex, age, schlcoll,educ, empstat,OCC,OCC2010,OCC1990, ind,ind1990, classwkr, ahrsworkt,wkswork1, uhrsworkly,classwly,workly,OCCLY,indly,OCC90LY,OCC1950, OCC50LY,ind90ly,OCC10LY, incwage, HOURWAGE,whymove, strechlk, whyptly)]

# subset


#saveRDS(acs, "../inputs/cps_00010.rds")
acs <- readRDS( "../inputs/cps_00010.rds")

# derive a 5-year age var
acs[, age_cat := paste0(floor(as.numeric(as.character(age))/5)*5,
                        " to ", 
                        floor(as.numeric(as.character(age))/5)*5 + 4)]

# make first dig var
#acs[, first_dig := substr(occ, 1,1)]

# make map for first dig categories
# map <- data.table(first_dig = as.character(0:9), 
#                   occ_categ = c("Professional", "Clerical", "Service",
#                                 "Agricultural, etc.", "Skilled", "Skilled",
#                                 "Semiskilled", "Semiskilled", "Unskilled",
#                                 "Unskilled"))
# acs <- merge(acs, map, by = "first_dig")

# # crosswalk to ppp
# ppp <- read_excel("../ref/CPI_U_RS.xlsx") %>% data.table
# ppp[1, year := 1940]
# ppp[1, cpi := 33]
# ppp[, year := as.character(year)]
# ppp[, xwalk_fac := cpi/369.8]
# acs <- merge(acs, ppp, by = "year")
# acs[, incwage := incwage/xwalk_fac]
# create log inc wage
acs[, log_incwage := log(incwage + 1)]

#
#acs <- acs[year %in% seq(1990,1999,3)]

# load occ_soc xwalk
occ_xwalk <- data.table(read_excel("../ref/nem-occcode-cps-crosswalk.xlsx"))
names(occ_xwalk) <- occ_xwalk[4,] %>% unlist()
occ_xwalk <- occ_xwalk[-(1:4),]
occ_xwalk[, OCCSOC := gsub("-", "", `Hybrid SOC Code`)]

# now create skills dataset
skills_2009 <- read.delim('../ref/db_14_0 2009.7/Skills.txt') %>% data.table()
skills_2013 <-  read.delim('../ref/db_18_0_2013.7/Skills.txt') %>% data.table()
skills_2018 <- read_excel("../ref/db_22_2_excel 2018.2/Skills.xlsx") %>% data.table()
skills_2009[, year := 2009]
skills_2013[, year := 2013]
skills_2018[, year := 2018]
setnames(skills_2018, names(skills_2018), gsub(" ", ".", names(skills_2018), fixed = T))
skills_2018[, `O.NET.SOC.Code` := `O*NET-SOC.Code`]
skills <- rbindlist(list(skills_2009, skills_2013, skills_2018), fill = T)
skills <- skills[, .(O.NET.SOC.Code, Element.Name, Scale.ID, Data.Value, Standard.Error, year)]
skills[, Element.Name := paste0("skl_", Element.Name)]
# add abilities
abilities_2009 <- read.delim('../ref/db_14_0 2009.7/Abilities.txt') %>% data.table()
abilities_2013 <-  read.delim('../ref/db_18_0_2013.7/Abilities.txt') %>% data.table()
abilities_2018 <- read_excel("../ref/db_22_2_excel 2018.2/Abilities.xlsx") %>% data.table()
abilities_2009[, year := 2009]
abilities_2013[, year := 2013]
abilities_2018[, year := 2018]
setnames(abilities_2018, names(abilities_2018), gsub(" ", ".", names(abilities_2018), fixed = T))
abilities_2018[, `O.NET.SOC.Code` := `O*NET-SOC.Code`]
abilities <- rbindlist(list(abilities_2009, abilities_2013, abilities_2018), fill = T)
abilities <- abilities[, .(O.NET.SOC.Code, Element.Name, Scale.ID, Data.Value, Standard.Error, year)]
abilities[, Element.Name := paste0("abl_", Element.Name)]

# add knowledge
knowledge_2009 <- read.delim('../ref/db_14_0 2009.7/Knowledge.txt') %>% data.table()
knowledge_2013 <-  read.delim('../ref/db_18_0_2013.7/Knowledge.txt') %>% data.table()
knowledge_2018 <- read_excel("../ref/db_22_2_excel 2018.2/Knowledge.xlsx") %>% data.table()
knowledge_2009[, year := 2009]
knowledge_2013[, year := 2013]
knowledge_2018[, year := 2018]
setnames(knowledge_2018, names(knowledge_2018), gsub(" ", ".", names(knowledge_2018), fixed = T))
knowledge_2018[, `O.NET.SOC.Code` := `O*NET-SOC.Code`]
knowledge <- rbindlist(list(knowledge_2009, knowledge_2013, knowledge_2018), fill = T)
knowledge <- knowledge[, .(O.NET.SOC.Code, Element.Name, Scale.ID, Data.Value, Standard.Error, year)]
knowledge[, Element.Name := paste0("knl_", Element.Name)]

#
skills <- rbindlist(list(skills, knowledge, abilities))

#
skills <- skills[Scale.ID == "LV"]
# reformate onet codes to merge
skills[, OCCSOC := gsub("-", "", substr(O.NET.SOC.Code,1,7))]
skills <- skills[,.(Data.Value = mean(Data.Value),
                    Standard.Error = mean(as.numeric(Standard.Error))), by = .(Element.Name,Scale.ID, OCCSOC)]

# chack to see which occ codes are missing
occ_xwalk[!OCCSOC %in% unique(skills$OCCSOC), unique(OCCSOC)]

# 
skills[, Element.Name := paste0(Element.Name, ".", Scale.ID)]
skills[,Data.Value := percent_rank(Data.Value), by = .(Element.Name, Scale.ID)]
skills_wide <- dcast(skills, OCCSOC   ~Element.Name, value.var = "Data.Value")
res.pca <- prcomp(skills_wide[,2:121], scale = TRUE, center = T)

# skills wide
skills_sum <- skills_wide
skills_sum[, pc1 := predict(res.pca, newdata = .SD)[,1], .SDcols = names(skills_sum)]
skills_sum[, pc2 := predict(res.pca, newdata = .SD)[,2], .SDcols = names(skills_sum)]
skills_sum[, pc3 := predict(res.pca, newdata = .SD)[,3], .SDcols = names(skills_sum)]
skills_sum[, pc4 := predict(res.pca, newdata = .SD)[,4], .SDcols = names(skills_sum)]

# skills_sum[, skl_tech_skill.LV := skl_Programming.LV + `skl_Complex Problem Solving.LV` +
#              `skl_Mathematics.LV`  + skl_Science.LV + `skl_Systems Analysis.LV` + 
#              skl_Troubleshooting.LV]
# skills_sum[, skl_tech_skill.IM := skl_Programming.IM + `skl_Complex Problem Solving.IM` +
#              `skl_Mathematics.IM`  + skl_Science.IM + `skl_Systems Analysis.IM` + 
#              skl_Troubleshooting.IM]
skills_sum[, average_value_skills := rowMeans(.SD), .SDcols = rownames(res.pca$rotation)[rownames(res.pca$rotation) %like% "LV" & rownames(res.pca$rotation) %like% "skl"]]
skills_sum[, average_value_abilities := rowMeans(.SD), .SDcols = rownames(res.pca$rotation)[rownames(res.pca$rotation) %like% "LV" & rownames(res.pca$rotation) %like% "abl"]]
skills_sum[, average_value_knowledge := rowMeans(.SD), .SDcols = rownames(res.pca$rotation)[rownames(res.pca$rotation) %like% "LV" & rownames(res.pca$rotation) %like% "knl"]]

skills_sum <- merge(skills_sum, occ_xwalk, by = "OCCSOC")


# collapse to OCCSOC
vars <- names(skills_wide)[-1]
skills_final <- skills_sum[,lapply(.SD, mean), .SDcols = vars, by = .(`CPS Code`, `CPS Occupational Title`)]
acs[, OCC2010 := as.character(OCC2010)]

#standardize occ2010 to match occ2019
acs[,.(OCC2010, OCC1990)] %>% unique -> temp
temp <- temp[!duplicated(temp$OCC2010)]
skills_final <- merge(skills_final, temp, by.x = "CPS Code", by.y = "OCC2010", all.x = T)
vars_temp <- names(skills_final)[!names(skills_final) %like% "CPS|OCC"]
skills_final[, (vars_temp) := lapply(.SD, mean, na.rm = T), by = OCC1990, .SDcols = vars_temp]
skills_final[,OCC1990 := NULL]

#clean up memory
rm(list = ls()[!ls() %in% c("acs", "vars", "weighted.var", "skills_final", "res.pca")])
```


```{r, echo = F}
# cheng xwalk
cheng <- data.table(readstata13::read.dta13("../ref/occ1950_mc_xwalk_70.dta"))
cheng[, occ1950 := gsub("[^A-Za-z0-9]", "", tolower(occ1950))]

# occ50 recode
occ50_recode <- fread("../ref/occ1950_recode.csv")
occ50_recode <- occ50_recode[,1:2]
names(occ50_recode) <- unlist(occ50_recode[1, ])
occ50_recode <- occ50_recode[-1,]
occ50_recode <- occ50_recode[!is.na(as.numeric(occ1950_num))]
occ50_recode[, occ1950 := gsub("[^A-Za-z0-9]", "", tolower(occ1950))]

# merge
cheng <- merge(cheng, occ50_recode[,.(occ1950, occ1950_num)], all.x = T)

#fix the stragglers
fix <- cheng[is.na(occ1950_num)]
candidates <- occ50_recode[!occ1950 %in% cheng$occ1950]

for(c.fix in 1:nrow(fix)){
  goal <- substr(fix[c.fix, occ1950],1,7)
  new <- candidates[candidates$occ1950 %like% goal, occ1950_num]
  if(length(new) == 1){fix[c.fix, new_occ1950_num := new]}
}


fix[is.na(new_occ1950_num), new_occ1950_num := c(43, 34, 44, 603, 16, 46, 605,94, 19,48,69,84,26,23,27,29)]

cheng <- merge(cheng, fix[,.(occ1950, new_occ1950_num)], by = "occ1950", all.x = T)
cheng[is.na(occ1950_num), occ1950_num := new_occ1950_num]
cheng[, occ1950_num := as.numeric(occ1950_num)]
cheng[, new_occ1950_num := NULL]
setnames(cheng, "occ1950_num", "OCC1950")
cheng[, occ1950 := NULL]

factorr <- function(x){ifelse(is.character(x), return(factor(x)), return(x))}
cheng[,names(cheng) := lapply(.SD, factorr), .SDcols = names(cheng)]

names(acs)[!names(acs) %like% "skl|knl|abl"] -> temp_vars
acs[, (temp_vars) := lapply(.SD, factorr), .SDcols = temp_vars]

#acs <- merge(acs, cheng, by.x = "OCC1950", by.y = "occ1950_num", all.x = T)
acs[,c("race", "hispan", "schlcoll","empstat","ahrsworkt",
       "wkswork1","uhrsworkly","classwly","workly",
       "HOURWAGE"):= NULL]

acs <- acs[cheng, on = "OCC1950"]

setnames(acs, c("mesoocc", "macroocc", "microocc"), paste0(c("mesoocc", "macroocc", "microocc"), "_current"))

setnames(cheng, "OCC1950", "OCC50LY")

acs <- acs[cheng, on = "OCC50LY"]

setnames(acs, c("mesoocc", "macroocc", "microocc"), paste0(c("mesoocc", "macroocc", "microocc"), "_ly"))

# loop over scheme and calculate concordance
for(c.scheme in  c( "mesoocc", "macroocc", "microocc")){
  acs[,paste0(c.scheme, "_conc") := get(paste0(c.scheme, "_ly")) == get(paste0(c.scheme, "_current")) ]
}

acs <- acs[!is.na(OCC2010)]


```



```{r, echo = F}
# merge it all
acs <- merge(acs, skills_final, 
             all.x = T,
             by.x = "OCC2010",
             by.y = "CPS Code")

# 

# merge on both new and old jobs
setnames(acs, vars, paste0(vars, "_current"))
setnames(acs, "CPS Occupational Title","CPS Occupational Title_current")
# merge it all
acs[, OCC10LY := as.character(OCC10LY)]
acs <- merge(acs, skills_final, 
             all.x = T,
             by.x = "OCC10LY",
             by.y = "CPS Code")

setnames(acs, vars, paste0(vars, "_ly"))
setnames(acs, "CPS Occupational Title","CPS Occupational Title_ly")

# subset to places where people have moved jobs
acs_moved <- acs[OCC2010 != OCC10LY]

# calculate flows
acs_flows <- acs[!is.na(`CPS Occupational Title_current`) & 
                   !is.na(`CPS Occupational Title_ly`),.(mvmt = .N), by = .(OCC2010, OCC10LY, `CPS Occupational Title_current`, `CPS Occupational Title_ly`)]

# graph top movement
temp <- acs_moved[, .N, by = OCC10LY] %>% .[order(N, decreasing = T)] %>% .[1:7, OCC10LY]
acs_flows[,rank := frankv(mvmt, order = -1L, ties.method = "first"), by = OCC10LY]
acs_flows[, OCC_title_ly := paste0(str_sub(`CPS Occupational Title_ly`, 1, 15), 
                                   "...")]
acs_flows[, OCC_title_current:= paste0(str_sub(`CPS Occupational Title_current`, 1, 15), 
                                       "...")]

acs_flows[, OCC_title_current := factor(OCC_title_current)]

# 
```


# Intro - Skills/Abilities/Knowledge

Similar to a few weeks ago, I've added data from ONET on abilities and knowledge, which are enumerated for each occupation on a similar scale to skills (0-1). Abilities in particular capture some physical aspects of occupations that are specific to less elite occupations, which will hopefully boost the predictive power of the following analyses in beingable to model the labor system.

## PCA analysis to visualize how the new variables are clustered

```{r}


fviz_pca_var(res.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE ,
             select.var = list(contrib = 15)    # Avoid text overlapping
)
fviz_pca_var(res.pca,
             axes = c(3,4),
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,# Avoid text overlapping,
             select.var = list(contrib = 15)
)

```

# Amongst occupational movers, which skills/knowledges/abilities are most correlated pre-/post-move

This section regresses each skill/ability/knowledge from last year against the same skill/ability/knowledge from the current year amongst people who have changed occupations. Reported values are the r-squared from this regression.

Some are highly correlated, while others are less. These weights contain information that could be used later to construct occupational groupings based on the salience of job qualities in determining the regidity of job transitions, but for now all skills/abilities/knowledges are considered equally in the construction of job categories.

```{r}
moved <- acs[OCC1990 != OCC90LY]

lmr <- function(data, var){
  lm_out <- lm(as.formula(paste0("`",var, "_current` ~ `", var, "_ly`")), data = data)
  return(data.table(slope = summary(lm_out)$coefficients[2, 1],
                    se = summary(lm_out)$coefficients[2, 2],
                    r_squared =summary(lm_out)$r.squared,
                    var = var))
}

lapply(vars[vars %like% "skl|abl|knl"], lmr, data = moved) %>% rbindlist() -> lmr_out_full

ggplot(lmr_out_full) + 
  geom_bar(aes(x = r_squared, y = reorder(var, r_squared)), stat = "identity") + 
  theme(axis.text = element_text(size = 3)) + 
  ggtitle("All Variables Sorted by R-Squared\nBetween Current/Former Occupation")

```

# See how skills/knowledges/abilities change pre/post job transition based on the context of the transition

The following graphs show the net change in average skill amongst certain classes of job movers: based on educational attainment, whether or not the job transition is in the same industry or a different industry, if the job transition was coupled with a physical relocation and the context of that relocation (moved due to lost job/moved due to promotion for example), if the worker was part time last year due to having been out of work, etc.

```{r}

for(c.skill in vars){
  #acs[, paste0(c.skill, "_distance") := abs(get(paste0(c.skill, '_current')) - get(paste0(c.skill, '_ly')))]
  acs[, paste0(c.skill, "_diff") := (get(paste0(c.skill, '_current')) - get(paste0(c.skill, '_ly')))]
  
}



acs[, ed_num := as.numeric(as.character(factor(educ,levels = levels(acs$educ), labels = c(0,0,0,2.5,1,2,3,4,5.5,
                                                                                          5,6,7.5, 7,8,9,10,11,11, 11, 11,12,
                                                                                          13,14,14,15,15,15,16,16,17,17,18,18,18,18,NA))))]

acs[ed_num <= 14, ed_categ := "Less than HS"]
acs[ed_num > 14, ed_categ := "College Plus"]

# subset to flows
skills_flows <- acs[OCC10LY != OCC2010]

# # graph distribution
# ggplot(skills_flows[!(OCC2010 == 4760 & OCC10LY == 4850),.SD, .SDcols = paste0(vars[!vars %like% "skills|pc"], "_distance")] %>% melt()) + 
#   geom_histogram(aes(x = value)) + 
#   facet_wrap(~variable) + 
#   xlim(0,1) + 
#   geom_abline(intercept = 2831.867, slope = -2831.867)

skills_flows[,colMeans(.SD, na.rm = T), .SDcols = names(skills_flows)[names(skills_flows) %like% "skl|abl|knl" &
                                                                        names(skills_flows) %like% "diff"]] %>% 
  melt(.) %>% 
  data.table(., keep.rownames = T) %>% 
  .[, cat := substr(rn, 1,3)] %>% 
  ggplot(.) + 
  geom_point(aes(y = rn, x = value, color = cat)) + 

    theme(axis.text.y = element_text(size = 3)) + 
  geom_vline(xintercept = 0, color = "red") + 
  ggtitle("All Occupational Changers")


skills_flows[ed_categ %like% "Less", colMeans(.SD, na.rm = T), .SDcols = names(skills_flows)[names(skills_flows) %like% "skl|abl|knl" &
                                                                                               names(skills_flows) %like% "diff"]] %>% 
  melt(.) %>% 
  data.table(., keep.rownames = T) %>% 
  .[, cat := substr(rn, 1,3)] %>% 
  ggplot(.) + 
  theme(axis.text.y = element_text(size = 3)) + 
  geom_point(aes(y = rn, x = value, color = cat)) + 
  geom_vline(xintercept = 0, color = "red")+ 
  ggtitle("Occupational Changers with Less than College Degree")

skills_flows[!ed_categ %like% "Less", colMeans(.SD, na.rm = T), .SDcols = names(skills_flows)[names(skills_flows) %like% "skl|abl|knl" &
                                                                                                names(skills_flows) %like% "diff"]] %>% 
  melt(.) %>% 
  data.table(., keep.rownames = T) %>% 
  .[, cat := substr(rn, 1,3)] %>% 
  ggplot(.) + 
  geom_point(aes(y = rn, x = value, color = cat)) + 
  theme(axis.text.y = element_text(size = 3)) + 
  geom_vline(xintercept = 0, color = "red")+ 
  ggtitle("Occupational Changers with College Degree+")



skills_flows[as.numeric(whymove) %in% c(5), colMeans(.SD, na.rm = T),
             .SDcols = names(skills_flows)[names(skills_flows) %like% "skl|abl|knl" &
                                             names(skills_flows) %like% "diff"]] %>% 
  melt(.) %>% 
  data.table(., keep.rownames = T) %>% 
  .[, cat := substr(rn, 1,3)] %>% 
  ggplot(.) + 
  geom_point(aes(y = rn, x = value, color = cat)) + 
  theme(axis.text.y = element_text(size = 3)) + 
  geom_vline(xintercept = 0, color = "red")+ 
  ggtitle("Occupational Changers Who Moved House\nfor New Job/Job Transfer")

skills_flows[as.numeric(whymove) %in% c(6), colMeans(.SD, na.rm = T),
             .SDcols = names(skills_flows)[names(skills_flows) %like% "skl|abl|knl" &
                                             names(skills_flows) %like% "diff"]] %>% 
  melt(.) %>% 
  data.table(., keep.rownames = T) %>% 
  .[, cat := substr(rn, 1,3)] %>% 
  ggplot(.) + 
  geom_point(aes(y = rn, x = value, color = cat)) + 
  theme(axis.text.y = element_text(size = 3)) + 
  geom_vline(xintercept = 0, color = "red")+ 
  ggtitle("Occupational Changers Who Moved House\nDue to Lost Job/to Look for Work+")

skills_flows[ind == indly, colMeans(.SD, na.rm = T),
             .SDcols = names(skills_flows)[names(skills_flows) %like% "skl|abl|knl" &
                                             names(skills_flows) %like% "diff"]] %>% 
  melt(.) %>% 
  data.table(., keep.rownames = T) %>% 
  .[, cat := substr(rn, 1,3)] %>% 
  ggplot(.) + 
  geom_point(aes(y = rn, x = value, color = cat)) + 
  geom_vline(xintercept = 0, color = "red")+ 
  theme(axis.text.y = element_text(size = 3)) + 
  ggtitle("Occupational Changers Within Same Industry")

skills_flows[ind != indly, colMeans(.SD, na.rm = T),
             .SDcols = names(skills_flows)[names(skills_flows) %like% "skl|abl|knl" &
                                             names(skills_flows) %like% "diff"]] %>% 
  melt(.) %>% 
  data.table(., keep.rownames = T) %>% 
  .[, cat := substr(rn, 1,3)] %>% 
  ggplot(.) + 
  geom_point(aes(y = rn, x = value, color = cat)) + 
  geom_vline(xintercept = 0, color = "red")+ 
  theme(axis.text.y = element_text(size = 3)) + 
  ggtitle("Occupational Changers Within Different Industry+")

skills_flows[as.numeric(strechlk) %in% 2:5, colMeans(.SD, na.rm = T),
             .SDcols = names(skills_flows)[names(skills_flows) %like% "skl|abl|knl" &
                                             names(skills_flows) %like% "diff"]] %>% 
  melt(.) %>% 
  data.table(., keep.rownames = T) %>% 
  .[, cat := substr(rn, 1,3)] %>% 
  ggplot(.) + 
  geom_point(aes(y = rn, x = value, color = cat)) + 
  geom_vline(xintercept = 0, color = "red")+ 
  theme(axis.text.y = element_text(size = 3)) + 
  ggtitle("Occupational Changers Who Were Out of Work\nAt Least One Week Last Year+")

skills_flows[as.numeric(whyptly) %in% 1, colMeans(.SD, na.rm = T),
             .SDcols = names(skills_flows)[names(skills_flows) %like% "skl|abl|knl" &
                                             names(skills_flows) %like% "diff"]] %>% 
  melt(.) %>% 
  data.table(., keep.rownames = T) %>% 
  .[, cat := substr(rn, 1,3)] %>% 
  ggplot(.) + 
  geom_point(aes(y = rn, x = value, color = cat)) + 
  theme(axis.text.y = element_text(size = 3)) + 
  geom_vline(xintercept = 0, color = "red") +
  ggtitle("Occupational Changers Who Were Part Time Last Year\nbecause They Couldn't Find a Full-Time Job")


```





```{r, echo = F}
# temp <- estimateNetwork(data = acs[,.SD, .SDcols = names(acs)[names(acs) %like% "LV_current" & !names(acs) %like% "tech_skill|pc"]] %>% setnames(., names(.), substr(names(.), 1,15)), 
#                         default = "EBICglasso")
# plot(temp, layout = "spring", labels = colnames(temp))
# plot(temp, layout = "spring")

rm(list = ls()[!ls() %in% c("acs", "vars", "weighted.var", "lmr_out_full")])
##################
acs <- copy(acs[complete.cases(acs[,.SD, .SDcols = names(acs)[names(acs) %like% "LV" & !names(acs) %like% "tech_skill|average|pc"]])])

## check out missing cases above!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1
# df <- data.table(rbind(acs[, .SD, .SDcols = names(acs)[names(acs) %like% "LV_current" & !names(acs) %like% "tech_skill|average|pc"]], acs[, .SD, .SDcols = names(acs)[names(acs) %like% "LV_ly" & !names(acs) %like% "tech_skill|average|pc"]] %>% setnames(., gsub("_ly", "_current", names(.)))))

df <- acs[!duplicated(acs$OCC2010), .SD, .SDcols = names(acs)[names(acs) %like% "skl|knl|abl|OCC2010" & names(acs) %like% "current|OCC2010"]]
df_occ <- df[,OCC2010]
df[, OCC2010 := NULL]

stats::kmeans(df, centers = 30) -> temp

df_temp <- data.table(OCC2010 = df_occ, kmeans_cluster = temp$cluster)

acs <- merge(acs, df_temp, by = "OCC2010")
setnames(acs, "kmeans_cluster", "kmeans_cluster_current")

df_temp <- data.table(OCC10LY = df_occ, kmeans_cluster = temp$cluster)
acs <- merge(acs, df_temp, by = "OCC10LY")
setnames(acs, "kmeans_cluster", "kmeans_cluster_ly")

#lapply(seq(5,105,10), optr) -> out


overlap_micro_count <- acs[,.(N = length(unique(OCC2010))), by = .(microocc_current, kmeans_cluster_current)]
overlap_micro_count[,kmeans_cluster_current := factor(kmeans_cluster_current, 
                                                      levels = acs[,.(mean = mean(average_value_skills_current)), by = kmeans_cluster_current] %>% .[order(mean, decreasing = T)] %>% .[,kmeans_cluster_current])]
# ggplot(overlap_micro_count) +
#   geom_tile(aes(y = microocc_current, x = kmeans_cluster_current, fill = N), alpha = .75) +
#   geom_text(aes(y = microocc_current, x = kmeans_cluster_current, label = N), size = 2) +
#   theme(axis.text.x = element_text(angle = 90)) +
#   ggtitle("Micro-class and Skills-Based Class Concordance\n(Number of Overlapping Occupations)")+
#   scale_fill_viridis_c( trans = "log10")
# now compute AMI
# ami_scores <- acs[complete.cases(acs[,.(kmeans_cluster_current, macroocc_current)]),
#                   .(macro = aricode::AMI(macroocc_current, kmeans_cluster_current), 
#                     meso = aricode::AMI(mesoocc_current, kmeans_cluster_current),
#                     micro = aricode::AMI(microocc_current, kmeans_cluster_current)), by = .(year)]
# 
# ami_scores %>% 
#   melt(., id.var = "year") %>% 
#   ggplot(.) + 
#   geom_line(aes(x = year, y = value, linetype = variable))

# judge concordance
acs[, kmeans_cluster_conc := ifelse(kmeans_cluster_current == kmeans_cluster_ly, 1,0)]
num_correct <- acs[OCC1950 != OCC50LY, colSums(.SD, na.rm = T), .SDcols = names(acs)[names(acs) %like% "conc"]]
total <- acs[OCC1950 != OCC50LY , nrow(.SD)]
num_correct <- num_correct/total
num_cats <- acs[OCC1950 != OCC50LY , lapply(.SD, FUN = function(x){length(unique(x))}), .SDcols = names(acs)[names(acs) %like% "occ_ly|bin_ly|kmeans_cluster_ly"]]

# get matrix of means and compute distances between each cluster
# geometric means
centers <- temp$centers
centers_long <- melt(centers)
centers_long <- merge(centers_long, centers_long, by = "Var2", allow.Cartesian = T)
centers_dist <- data.table(centers_long)[,.(geo_mean_dist = mean(abs(value.x - value.y))),
                                         by = .(Var1.x, Var1.y)]
setnames(centers_dist, c("kmeans_cluster_current", "kmeans_cluster_ly", "geo_mean_dist"))

#
acs <- merge(acs, centers_dist, by = c("kmeans_cluster_current", "kmeans_cluster_ly"))

#graph dist
# ggplot(acs[OCC2010 != OCC10LY]) + 
#   geom_density(aes(x = geo_mean_dist))
# 
# ggplot(acs[OCC2010 != OCC10LY & ind == indly]) + 
#   geom_density(aes(x = geo_mean_dist))

#
acs[, source_kmeans_N := .N, by = kmeans_cluster_ly]

acs[, kmeans_cluster_current := factor(kmeans_cluster_current, 
                                       levels = centers_dist[kmeans_cluster_current == 1] %>%
                                         .[order(geo_mean_dist)] %>% .[,kmeans_cluster_ly])]
acs[, kmeans_cluster_ly := factor(kmeans_cluster_ly, 
                                  levels = centers_dist[kmeans_cluster_current == 1] %>%
                                    .[order(geo_mean_dist)] %>% .[,kmeans_cluster_ly])]


# acs[OCC10LY != OCC2010,.(N = .N, source_kmeans_N = unique(source_kmeans_N)),
#     by= .(kmeans_cluster_current, kmeans_cluster_ly)] %>% 
#   .[, total := sum(N), by = kmeans_cluster_ly] %>% 
#   .[, prop := N/source_kmeans_N] %>% 
#   .[N >= 10] %>% 
#   ggplot() + 
#   geom_point(aes(y = (kmeans_cluster_current), x = (kmeans_cluster_ly), color = prop, size = N)) + 
#   scale_color_viridis_c(trans = "log10") +
#   scale_radius(trans = "log10")+
#   geom_abline(yintercept = 0, slope = 1, color= "red")
```


# K-Means clustering as a means of creating occupational groupings

The following graph shows how, as k increases, the within-cluster variance decreases. K-Means clustering is performed on the skills data only, and so it is NOT weighted by the prevalence of each occupation in the data. Starting at around 30 clusters, the marginal utility of each additional cluster begins to level off, perhaps indicating that this is about the most information that can be extracted from these data. 

```{r}
df <- acs[!duplicated(acs$OCC1990), .SD, .SDcols = names(acs)[names(acs) %like% "skl|knl|abl|OCC1990" & names(acs) %like% "current|OCC1990"]]
df_occ <- df[,OCC1990]
df[, OCC1990 := NULL]

acs[, c(paste0(vars, "_current"), paste0(vars, "_ly")) := NULL]

optr <- function(k){
  stats::kmeans(df, centers = k) -> temp2
  return(data.table(k =k, tot_withinss = temp2$tot.withinss))
}

lapply(1:250, optr) %>% rbindlist -> optr_out
ggplot(optr_out) + 
  geom_point(aes(x = k, y = tot_withinss))

```

### See how different k affects mobility

Set number of k to correspond with meso, micro, macro class schemas and some other random numbers.

k = {4,9,67, 20,30,40,50,80,90,100,120}

The following code creates k clusters based on the skills/abilities/knowledge data.

```{r}

## toggle whether its weighted or not
#df <- df * lmr_out_full$r_squared

c(4,9,67, 20,30,40,50,80,90,100,120) -> k_cand

for(k in k_cand){
  stats::kmeans(df, centers = k) -> temp2
  df_temp2 <- data.table(OCC1990 = df_occ, kmeans_cluster = temp2$cluster)
  setnames(df_temp2, "kmeans_cluster", paste0("kmeans_cluster_", k, "_current"))
  df_temp2[, paste0("kmeans_cluster_", k, "_current") := paste0(",", get(paste0("kmeans_cluster_", k, "_current")), 
                                                                ",")]
  acs <- merge(acs, df_temp2, by = "OCC1990")
  
  df_temp3 <- data.table(OCC90LY = df_occ, kmeans_cluster = temp2$cluster)
  setnames(df_temp3, "kmeans_cluster", paste0("kmeans_cluster_", k, "_ly"))
  df_temp3[, paste0("kmeans_cluster_", k, "_ly") := paste0(",", get(paste0("kmeans_cluster_", k, "_ly")), 
                                                           ",")]
  
  acs <- merge(acs, df_temp3, by = "OCC90LY")
  
  
  centers <- temp2$centers
  
  melt(centers) %>% data.table() %>% .[,.(value = sum(value)), by = Var1] %>% .[order(value, decreasing = T), Var1] %>% .[1] -> high_skill
  
  centers_long <- melt(centers)
  centers_long <- data.table(centers_long)
  centers_long[, Var1 := paste0(",", Var1, ",")]
  centers_long <- merge(centers_long, centers_long, by = "Var2", allow.cartesian = T)
  centers_dist <- data.table(centers_long)[,.(geo_mean_dist = mean(abs(value.x - value.y))),
                                           by = .(Var1.x, Var1.y)]
  setnames(centers_dist, c(paste0("kmeans_cluster_", k, "_current"), 
                           paste0("kmeans_cluster_", k, "_ly"), paste0("geo_means_", k, "_dist")))
  
  # create vectors of nearest neighbors
  for(k_temp in paste0(",", 1:k, ",")){
    centers_dist[get(paste0("kmeans_cluster_", k, "_ly")) == k_temp] %>% 
      .[order(get(paste0("geo_means_", k, "_dist")))] %>%
      .[,get(paste0("kmeans_cluster_", k, "_current"))] %>% 
      .[1:3] %>% 
      paste0(., collapse = "|") -> tempp
    centers_dist[get(paste0("kmeans_cluster_", k, "_ly")) == k_temp,
                 paste0("kmeans_cluster_rank_3_", k, "_conc"):= 
                   ifelse(get(paste0("kmeans_cluster_", k, "_current")) %like% tempp, 1,0) ]
  }
  
  
  
  #
  acs <- merge(acs, centers_dist, by = c(paste0("kmeans_cluster_", k, "_current"),
                                         paste0("kmeans_cluster_", k, "_ly")))
  centers_dist[,   paste0("kmeans_cluster_", k, "_ly") := 
                 as.numeric(gsub(",", "", get(  paste0("kmeans_cluster_", k, "_ly"))))]
  centers_dist[,   paste0("kmeans_cluster_", k, "_current") := 
                 as.numeric(gsub(",", "", get(  paste0("kmeans_cluster_", k, "_current"))))]
  acs[,   paste0("kmeans_cluster_", k, "_ly") :=
        as.numeric(gsub(",", "", get(  paste0("kmeans_cluster_", k, "_ly"))))]
  acs[,   paste0("kmeans_cluster_", k, "_current") := 
        as.numeric(gsub(",", "", get(  paste0("kmeans_cluster_", k, "_current"))))]
  
  acs[,paste0("kmeans_cluster_", k, "_conc") := ifelse(get(paste0("kmeans_cluster_", k, "_current")) == 
                                                         get(paste0("kmeans_cluster_", k, "_ly")),1,0)]
  
  acs[, paste0("source_kmeans_", k, "_N") := .N, by = get(paste0("kmeans_cluster_", k, "_ly"))]
  
  acs[, paste0("kmeans_cluster_", k, "_current") := factor(get(paste0("kmeans_cluster_", k, "_current")), 
                                                           levels = centers_dist[get(paste0("kmeans_cluster_", k, "_current")) == high_skill] %>%
                                                             .[order(get(paste0("geo_means_", k, "_dist")))] %>%
                                                             .[,get(paste0("kmeans_cluster_", k, "_ly"))])]
  acs[, paste0("kmeans_cluster_", k, "_ly") := factor(get(paste0("kmeans_cluster_", k, "_ly")), 
                                                      levels = centers_dist[get(paste0("kmeans_cluster_", k, "_current")) == high_skill] %>%
                                                        .[order(get(paste0("geo_means_", k, "_dist")))] %>%
                                                        .[,get(paste0("kmeans_cluster_", k, "_ly"))])]
  
  
  
  
}


```

### Check concordance with meso/micro/macro class schedules

4, 9, and 67 correspond with micro, meso, and macro respectively. While perfect concordance is less good, if we extend the reach of the algorithm to people in either of the top 3 closest skills categories, we see improved performance.

```{r, results = 'asis'}


### check concordance of micro meso and macro first

num_correct <- acs[OCC1950 != OCC50LY & !is.na(kmeans_cluster_30_current),
                   colSums(.SD, na.rm = T), .SDcols = names(acs)[names(acs) %like% "conc"]]
total <- acs[OCC1950 != OCC50LY , nrow(.SD)]
num_correct <- num_correct/total
num_cats <- acs[OCC1950 != OCC50LY, lapply(.SD, FUN = function(x){length(unique(x))}), .SDcols = names(acs)[names(acs) %like% "occ_ly|bin_ly"]]

num_correct[names(num_correct) %like% "meso|macro|micro|4_|9_|67_"] -> out
out <- melt(out) %>% data.table(., keep.rownames = T)
out[,id := c(2,1,3,1,1,2,2,3,3)]
out[,method := c("Traditional","Traditional","Traditional",
                 "Skills-Based (Fuzzy)","Skills-Based",
                 "Skills-Based (Fuzzy)","Skills-Based",
                 "Skills-Based (Fuzzy)","Skills-Based")]
out <- dcast(out, method ~ id)
setnames(out, c("Method", "Micro (4)", "Meso (9)", "Macro (67)"))
xtable::xtable(out)
```

### show overall job migration

These graphs are 2D versions of the 3d graphs used in the Grusky Microclass paper

```{r}

for(k in k_cand){
  acs[OCC90LY != OCC1990,.(N = .N, source_kmeans_N = unique(get(paste0("source_kmeans_", k, "_N") ))),
      by= .(get(paste0("kmeans_cluster_", k, "_current")), get(paste0("kmeans_cluster_", k, "_ly")))] %>% 
    .[, total := sum(N), by = get.1] %>% 
    .[, prop := N/source_kmeans_N] %>% 
    .[N >= 10] %>% 
    ggplot() + 
    geom_point(aes(y = get,
                   x = get.1, color = prop, size = N)) + 
    scale_color_viridis_c(trans = "log10") +
    scale_radius(trans = "log10")+
    geom_abline(yintercept = 0, slope = 1, color= "red") +
    theme(axis.text.x = element_text(angle = 90), 
          axis.text = element_text(size = 5)) + 
    scale_x_discrete(drop = F)+
    scale_y_discrete(drop = F) +
    ggtitle(paste0("K = ", k))-> gg
  print(gg)
}
```

### These graphs show the distribution of skills distances for all occupational migrants

```{r}
for(k in k_cand){
  ggplot(acs[OCC90LY != OCC1990])+
    geom_density(aes(x = get(paste0("geo_means_", k, "_dist")))) + 
    ggtitle(paste0("K = ", k)) -> gg
  print(gg)
}
```



```{r}
# df_temp <- data.table(OCC2010 = df_occ, kmeans_cluster = temp$cluster)
# 
# acs <- merge(acs, df_temp, by = "OCC2010")
# setnames(acs, "kmeans_cluster", "kmeans_cluster_current")
# 
# df_temp <- data.table(OCC10LY = df_occ, kmeans_cluster = temp$cluster)
# acs <- merge(acs, df_temp, by = "OCC10LY")
# setnames(acs, "kmeans_cluster", "kmeans_cluster_ly")
# 
# # optimize k
# optr <- function(k){
#   stats::kmeans(df, centers = k) -> temp2
#   return(temp2$tot.withinss)
# }


# gg_list <- list()
# q <- 0
# for(k in seq(10,110,20)){
#   q <- q + 1
#   print(k)
#   df <- data.table(rbind(acs[, .SD, .SDcols = names(acs)[names(acs) %like% "LV_current" & !names(acs) %like% "tech_skill|pc"]], acs[, .SD, .SDcols = names(acs)[names(acs) %like% "LV_ly" & !names(acs) %like% "tech_skill|pc"]] %>% setnames(., gsub("_ly", "_current", names(.)))))
#   stats::kmeans(df, centers = k) -> temp
#   
#   # assign clusters
#   acs[, kmeans_cluster_current := temp$cluster[1:nrow(acs)]]
#   acs[, kmeans_cluster_ly := temp$cluster[(nrow(acs) + 1):(nrow(acs)*2)]]
#   
#   #
#   # get matrix of means and compute distances between each cluster
#   # geometric means
#   centers <- temp$centers
#   centers_long <- melt(centers)
#   centers_long <- merge(centers_long, centers_long, by = "Var2", allow.Cartesian = T)
#   centers_dist <- data.table(centers_long)[,.(geo_mean_dist = prod(abs(value.x - value.y)) ^ (1/length(value.x))),
#                                            by = .(Var1.x, Var1.y)]
#   setnames(centers_dist, c("kmeans_cluster_current", "kmeans_cluster_ly", "geo_mean_dist"))
#   
#   #
#   acs[, geo_mean_dist := NULL]
#   acs <- merge(acs, centers_dist, by = c("kmeans_cluster_current", "kmeans_cluster_ly"))
#   
#   #
#   acs[, source_kmeans_N := .N, by = kmeans_cluster_ly]
#   centers <- data.table(centers)
#   centers[,total_skills := rowSums(.SD), .SDcols = names(centers)]
#   
#   acs[, kmeans_cluster_current := factor(kmeans_cluster_current, 
#                                          levels = centers[, order(total_skills)])]
#   acs[, kmeans_cluster_ly := factor(kmeans_cluster_ly, 
#                                     levels = centers[, order(total_skills)])]
#   
#   
#   gg <- acs[OCC10LY != OCC2010,.(N = .N, source_kmeans_N = unique(source_kmeans_N)),
#             by= .(kmeans_cluster_current, kmeans_cluster_ly)] %>% 
#     .[, total := sum(N), by = kmeans_cluster_ly] %>% 
#     .[, prop := N/source_kmeans_N] %>% 
#     .[N >= 10] %>% 
#     ggplot()+
#       geom_point(aes(y = (kmeans_cluster_current), x = (kmeans_cluster_ly), color = prop, size = N)) + 
#   scale_color_viridis_c(trans = "log10") +
#   scale_radius(trans = "log10")+
#   geom_abline(yintercept = 0, slope = 1, color= "red") +
#   scale_x_discrete(labels = centers[, order(total_skills)],
#                    breaks = centers[, order(total_skills)], drop = F)+
#   scale_y_discrete(labels = centers[, order(total_skills)],
#                    breaks = centers[, order(total_skills)], drop = F)+
#   theme(axis.text.x = element_text(angle = 90))
#   
#   print(gg)
# 
# }


```

### See how well each scheme predicts log earnings

```{r}
aicr <- function(c.year, data = acs){
  mod <- lm(log_incwage ~ as.factor(kmeans_cluster_67_current), data[year == c.year])
  mod2 <- lm(log_incwage ~ as.factor(microocc_current), data[year == c.year])
  mod3 <- lm(log_incwage ~ as.factor(kmeans_cluster_9_current), data[year == c.year])
  mod4<- lm(log_incwage ~ as.factor(mesoocc_current), data[year == c.year])
  return(data.table(year = c.year, cluster_67 = summary(mod)$r.squared,
             micro =  summary(mod2)$r.squared,
             cluster_9 = summary(mod3)$r.squared,
             meso = summary(mod4)$r.squared
             ))
}

lapply( unique(acs$year), aicr) %>% rbindlist() -> out
ggplot(melt(out, id.var = 'year'))+ 
  geom_line(aes(x = year, y = value, color = variable))
```